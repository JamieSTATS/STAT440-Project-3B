{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99ee9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4b59618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/21546739/load-data-from-txt-with-pandas\n",
    "#https://stackoverflow.com/questions/40011531/in-pandas-when-using-read-csv-how-to-assign-a-nan-to-a-value-thats-not-the\n",
    "\n",
    "\n",
    "\n",
    "# Read data, change missing values to 'NaN'\n",
    "\n",
    "Xtrain_raw = pd.read_csv('Xtrain.txt', sep =\" \", index_col=0, dtype='float64',\n",
    "                    na_values=['?','NaN'])\n",
    "Xtest_raw = pd.read_csv('Xtest.txt', sep =\" \", index_col=0, dtype='float64',\n",
    "                    na_values=['?','NaN'])\n",
    "\n",
    "Ytrain_raw = pd.read_csv('Ytrain.txt', sep =\",\", index_col=0, dtype='float64',\n",
    "                    na_values=['?','NaN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14c4ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153287, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fc90420d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153287, 75)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afa8fdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 75)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_raw.shape\n",
    "#Xtest_raw.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "efdffb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/51207491/function-to-replace-nan-values-in-a-dataframe-with-mean-of-the-related-column\n",
    "#Replace NaN with column means in Xtrain\n",
    "Xtrain_filled = Xtrain_raw.apply(lambda x: x.fillna(x.mean())) \n",
    "#print(Xtrain_filled.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9f62b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for other data-sets\n",
    "\n",
    "Ytrain_filled = Ytrain_raw.apply(lambda x: x.fillna(x.mean())) \n",
    "Xtest_filled = Xtest_raw.apply(lambda x: x.fillna(x.mean())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7b628bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_filled shape:  (50000, 75)\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the training and test sets and check to make sure that all observations from the dataset are there\n",
    "\n",
    "Xmerged_raw = pd.concat([Xtrain_raw, Xtest_raw])\n",
    "print('X_filled shape: ', Xtest_raw.shape)\n",
    "#Xmerged_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc2c5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xraw_sorted = Xmerged_raw.sort_index(axis=0)\n",
    "#Xraw_sorted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "213c1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the last ten rows (all -9 in test set)\n",
    "Xraw_clean=Xraw_sorted.drop(labels=[ '#H04', '#H05', '#H06', '#H07', '#H08', '#H09','#I01', '#I02', '#I03','#I04'], axis=1)\n",
    "#print(Xraw_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ac9f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as a csv file for use in R\n",
    "\n",
    "Xraw_clean.to_csv('/Users/Jamie/Xraw_clean.csv', index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "311153c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do the same for the other data sets\n",
    "\n",
    "Xtrain_clean=Xtrain_filled.drop(labels=[ '#H04', '#H05', '#H06', '#H07', '#H08', '#H09','#I01', '#I02', '#I03','#I04'], axis=1)\n",
    "Xtest_clean=Xtest_filled.drop(labels=[ '#H04', '#H05', '#H06', '#H07', '#H08', '#H09','#I01', '#I02', '#I03','#I04'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "938f6e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfilled_sorted = Xraw_clean.apply(lambda x: x.fillna(x.mean()))\n",
    "#Xfilled_sorted.info\n",
    "#type(Xfilled_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "154ed90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(Xfilled_sorted)\n",
    "#Xsample = Xfilled_sorted.sample(n = 10, random_state=1)\n",
    "#type(Xsample)\n",
    "#Xfilled_sorted.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d105a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xsample_resetindex = Xsample.reset_index()\n",
    "#Xsample_noindex = Xsample_resetindex.drop(['Id'], axis=1)\n",
    "#Xint_ind=Xfilled_sorted['Id'].astype(str)\n",
    "#TwoXcolumn=Xfilled_sorted.iloc['#A01']\n",
    "\n",
    "#TwoXcolumn_resetindex = TwoXcolumn.reset_index()\n",
    "#TwoXcolumn_noindex = TwoXcolumn_resetindex.drop(['Id'], axis=1)\n",
    "#Twocolumnsdf = TwoXcolumn.copy\n",
    "#Xsample_noindex\n",
    "#sns.pairplot(TwoXcolumn_noindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ef2a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge training data sets\n",
    "train_merged= Xtrain_clean.merge(Ytrain_filled, how='left', on='Id')\n",
    "#print(train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6d0e513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the Id column and reset the index\n",
    "\n",
    "train_merged_resetindex = train_merged.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae56dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merged_noindex = train_merged_resetindex.drop(['Id'], axis=1)\n",
    "#print(train_merged_noindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "694b5cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling [some code reused from project 2]\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor,Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0ed8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_merged['Value'].copy()\n",
    "X = train_merged.drop(['Value'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e93f0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e38d6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8c6dc00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jamie/venv/lib/python3.9/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# standardize for sample sets and Xtest\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "Xtest_clean_transformed= scaler.transform(Xtest_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c2c030ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeModel = Ridge(alpha=20).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b3ef4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_predictions = RidgeModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b905fa75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.64121745271793"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, Ridge_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d0a61fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ridge_g_search = GridSearchCV(estimator = Ridge(), param_grid = {'alpha': [1.0, 2.0, 3.0, 6.0, 10, 15, 20, 30, 50, 60]}, cv = 3, n_jobs = 1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a4e6e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END ..........................................alpha=1.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=1.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=2.0; total time=   0.2s\n",
      "[CV] END ..........................................alpha=2.0; total time=   0.2s\n",
      "[CV] END ..........................................alpha=2.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=3.0; total time=   0.2s\n",
      "[CV] END ..........................................alpha=3.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=3.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=6.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=6.0; total time=   0.1s\n",
      "[CV] END ..........................................alpha=6.0; total time=   0.1s\n",
      "[CV] END ...........................................alpha=10; total time=   0.1s\n",
      "[CV] END ...........................................alpha=10; total time=   0.1s\n",
      "[CV] END ...........................................alpha=10; total time=   0.1s\n",
      "[CV] END ...........................................alpha=15; total time=   0.1s\n",
      "[CV] END ...........................................alpha=15; total time=   0.1s\n",
      "[CV] END ...........................................alpha=15; total time=   0.1s\n",
      "[CV] END ...........................................alpha=20; total time=   0.1s\n",
      "[CV] END ...........................................alpha=20; total time=   0.1s\n",
      "[CV] END ...........................................alpha=20; total time=   0.1s\n",
      "[CV] END ...........................................alpha=30; total time=   0.2s\n",
      "[CV] END ...........................................alpha=30; total time=   0.1s\n",
      "[CV] END ...........................................alpha=30; total time=   0.1s\n",
      "[CV] END ...........................................alpha=50; total time=   0.1s\n",
      "[CV] END ...........................................alpha=50; total time=   0.1s\n",
      "[CV] END ...........................................alpha=50; total time=   0.1s\n",
      "[CV] END ...........................................alpha=60; total time=   0.1s\n",
      "[CV] END ...........................................alpha=60; total time=   0.1s\n",
      "[CV] END ...........................................alpha=60; total time=   0.1s\n",
      "{'alpha': 60}\n"
     ]
    }
   ],
   "source": [
    "ridge_g_search.fit(x_train, y_train);\n",
    "print(ridge_g_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d9a0356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f247d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDtest = SGDRegressor(loss = 'huber', alpha = 0.000001, epsilon = 0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bae00e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_test_predictions = SGDtest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c3d8d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.34306606129916"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, SGD_test_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4bb0d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'alpha':[0.1, 0.001,],\n",
    "              'learning_rate':['adaptive'],\n",
    "              'max_iter':[400, 600],\n",
    "              'penalty':['l2','l1','elasticnet'],\n",
    "              'loss':['huber', 'squared_epsilon_insensitive', 'squared_error'],\n",
    "              'eta0': [0.01, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0efa046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_ = SGDRegressor(random_state = 1)\n",
    "g_search = GridSearchCV(estimator = sgd_, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d8d5b924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.7s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.7s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   2.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   2.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   2.7s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   2.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   3.9s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   4.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   4.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  10.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  11.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  11.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  10.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=   9.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=   9.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   4.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   4.4s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   4.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  11.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  11.4s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  10.7s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  10.0s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  10.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  12.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   3.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   2.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   3.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   8.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   6.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   6.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   5.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   5.1s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   6.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   2.9s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   3.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   5.8s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  13.2s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=   6.3s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=   6.5s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   5.6s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   4.9s\n",
      "[CV] END alpha=0.1, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   5.1s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   4.1s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   4.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   3.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   3.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   4.6s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   4.6s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.1s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   7.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.6s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=  11.3s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   7.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   8.5s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  19.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  17.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  12.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  14.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  15.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   7.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   8.0s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.3s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  20.3s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  17.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  17.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  12.5s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  14.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  14.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   3.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   4.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   4.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  11.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  14.5s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  10.4s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   8.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   8.4s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   9.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   4.6s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   4.5s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   4.3s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  11.4s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  11.2s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  11.8s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   8.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   8.7s\n",
      "[CV] END alpha=0.1, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   8.7s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.7s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   5.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   4.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   5.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   5.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   4.8s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   5.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   3.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.9s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.9s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   5.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   7.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   5.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   4.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   4.7s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   4.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  13.6s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  19.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  10.8s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  14.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  13.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  13.7s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  12.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  13.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=   9.9s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=   9.5s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  10.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   6.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   6.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   5.7s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  18.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  19.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  18.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  10.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  10.5s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  12.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   6.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   5.1s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   5.4s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  17.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  17.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  20.2s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  10.3s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  11.0s\n",
      "[CV] END alpha=0.1, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  12.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   1.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   1.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   3.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   3.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   2.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   2.5s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.7s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   9.8s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=  11.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=  11.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  19.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  15.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  18.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  17.7s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  18.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=  10.3s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   9.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   9.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  16.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  14.8s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  14.7s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  14.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  14.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  12.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   3.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   3.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   6.9s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   6.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   6.1s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   7.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   6.5s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   6.8s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   4.0s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   3.4s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   3.5s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=   7.7s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=   6.7s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=   6.6s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   9.5s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   8.2s\n",
      "[CV] END alpha=0.001, eta0=0.01, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   8.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.6s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.0s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   3.7s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   4.0s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   6.0s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   5.1s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   3.8s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   3.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.3s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.8s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   3.1s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   3.8s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.6s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   3.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   8.8s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   9.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   8.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  16.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  17.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  16.2s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  17.2s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   8.7s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   8.8s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   8.3s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  14.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  13.2s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  14.1s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  16.1s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  15.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  18.2s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   5.3s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   4.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   5.9s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  12.3s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  10.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=   9.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  14.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=   9.6s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  13.1s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   5.5s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   4.7s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   5.3s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  12.7s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  10.4s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  11.6s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=   9.2s\n",
      "[CV] END alpha=0.001, eta0=1, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  12.0s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.7s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l2; total time=   2.4s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   4.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   5.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=l1; total time=   5.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   4.6s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   5.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=400, penalty=elasticnet; total time=   5.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.1s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l2; total time=   2.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   4.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   6.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=l1; total time=   5.6s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.6s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=huber, max_iter=600, penalty=elasticnet; total time=   4.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   6.4s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   6.0s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l2; total time=   7.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  12.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  14.0s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=l1; total time=  11.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  15.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  11.6s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=400, penalty=elasticnet; total time=  13.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   6.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l2; total time=   7.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  12.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  14.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=l1; total time=  11.1s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  13.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  12.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=600, penalty=elasticnet; total time=  12.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   8.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=   9.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l2; total time=  10.4s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  16.7s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  17.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=l1; total time=  17.1s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  18.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  17.8s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=400, penalty=elasticnet; total time=  19.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   9.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   8.6s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l2; total time=   9.2s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  15.7s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  15.5s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=l1; total time=  16.3s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  16.9s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  17.7s\n",
      "[CV] END alpha=0.001, eta0=10, learning_rate=adaptive, loss=squared_error, max_iter=600, penalty=elasticnet; total time=  19.5s\n",
      "{'alpha': 0.001, 'eta0': 1, 'learning_rate': 'adaptive', 'loss': 'squared_epsilon_insensitive', 'max_iter': 400, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "g_search.fit(x_train, y_train);\n",
    "print(g_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9466bd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdtest = SGDRegressor(alpha = 0.001, learning_rate= 'adaptive', loss = 'squared_epsilon_insensitive', max_iter= 400 ).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ca26a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_test_predictions = sgdtest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8aa43c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.640956903016304"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, SGD_test_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25303623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1999c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABregr = AdaBoostRegressor(random_state=1, loss='square', n_estimators=80, learning_rate=0.01)\n",
    "ABModel = ABregr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "35523cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_test_predictions = ABModel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1860bfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.08978372421733"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, AB_test_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8f8c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c54aa67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'random_state':[1], 'n_estimators':[80],\n",
    "              'learning_rate':[.01, 0.5, 1.0, 3.0],\n",
    "              'loss':['linear', 'square', 'exponential']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bd77e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_ = AdaBoostRegressor(random_state = 1)\n",
    "ABg_search = GridSearchCV(estimator = ab_, param_grid = param_grid, cv = 3, n_jobs = 1, verbose = 2, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "142dd8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] END learning_rate=0.01, loss=linear, n_estimators=80, random_state=1; total time= 2.7min\n",
      "[CV] END learning_rate=0.01, loss=linear, n_estimators=80, random_state=1; total time= 2.9min\n",
      "[CV] END learning_rate=0.01, loss=linear, n_estimators=80, random_state=1; total time= 3.3min\n",
      "[CV] END learning_rate=0.01, loss=square, n_estimators=80, random_state=1; total time= 2.7min\n",
      "[CV] END learning_rate=0.01, loss=square, n_estimators=80, random_state=1; total time= 2.6min\n",
      "[CV] END learning_rate=0.01, loss=square, n_estimators=80, random_state=1; total time= 2.7min\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=80, random_state=1; total time= 2.4min\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=80, random_state=1; total time= 2.6min\n",
      "[CV] END learning_rate=0.01, loss=exponential, n_estimators=80, random_state=1; total time= 2.6min\n",
      "[CV] END learning_rate=0.5, loss=linear, n_estimators=80, random_state=1; total time= 2.4min\n",
      "[CV] END learning_rate=0.5, loss=linear, n_estimators=80, random_state=1; total time= 2.0min\n",
      "[CV] END learning_rate=0.5, loss=linear, n_estimators=80, random_state=1; total time= 1.5min\n",
      "[CV] END learning_rate=0.5, loss=square, n_estimators=80, random_state=1; total time= 1.6min\n",
      "[CV] END learning_rate=0.5, loss=square, n_estimators=80, random_state=1; total time= 1.3min\n",
      "[CV] END learning_rate=0.5, loss=square, n_estimators=80, random_state=1; total time= 1.4min\n",
      "[CV] END learning_rate=0.5, loss=exponential, n_estimators=80, random_state=1; total time= 1.8min\n",
      "[CV] END learning_rate=0.5, loss=exponential, n_estimators=80, random_state=1; total time= 1.8min\n",
      "[CV] END learning_rate=0.5, loss=exponential, n_estimators=80, random_state=1; total time= 2.0min\n",
      "[CV] END learning_rate=1.0, loss=linear, n_estimators=80, random_state=1; total time=  53.3s\n",
      "[CV] END learning_rate=1.0, loss=linear, n_estimators=80, random_state=1; total time=  48.1s\n",
      "[CV] END learning_rate=1.0, loss=linear, n_estimators=80, random_state=1; total time= 1.3min\n",
      "[CV] END learning_rate=1.0, loss=square, n_estimators=80, random_state=1; total time= 1.1min\n",
      "[CV] END learning_rate=1.0, loss=square, n_estimators=80, random_state=1; total time= 1.1min\n",
      "[CV] END learning_rate=1.0, loss=square, n_estimators=80, random_state=1; total time= 1.3min\n",
      "[CV] END learning_rate=1.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.5min\n",
      "[CV] END learning_rate=1.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.6min\n",
      "[CV] END learning_rate=1.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.9min\n",
      "[CV] END learning_rate=3.0, loss=linear, n_estimators=80, random_state=1; total time= 1.1min\n",
      "[CV] END learning_rate=3.0, loss=linear, n_estimators=80, random_state=1; total time=  18.7s\n",
      "[CV] END learning_rate=3.0, loss=linear, n_estimators=80, random_state=1; total time=  21.5s\n",
      "[CV] END learning_rate=3.0, loss=square, n_estimators=80, random_state=1; total time=  18.2s\n",
      "[CV] END learning_rate=3.0, loss=square, n_estimators=80, random_state=1; total time=  15.8s\n",
      "[CV] END learning_rate=3.0, loss=square, n_estimators=80, random_state=1; total time=  20.8s\n",
      "[CV] END learning_rate=3.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.1min\n",
      "[CV] END learning_rate=3.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.3min\n",
      "[CV] END learning_rate=3.0, loss=exponential, n_estimators=80, random_state=1; total time= 1.1min\n",
      "{'learning_rate': 0.01, 'loss': 'square', 'n_estimators': 80, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "ABg_search.fit(x_train, y_train);\n",
    "print(ABg_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf403fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First a simple Linear Regression Test\n",
    "\n",
    "LinModel = LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cfcedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lin_predictions = LinModel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "649bb578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.112893460636878"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, Lin_predictions, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598c318d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5e1541b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest_Lin_predictions = LinModel.predict(Xtest_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd783207",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD_predictions = sgdtest.predict(Xtest_clean_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3c1544ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB_predictions = ABModel.predict(Xtest_clean_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cccf75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the sample predictions\n",
    "pred = pd.read_csv('pred.txt', sep =\",\", index_col=0, dtype= {'Value': np.float64})        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c5d9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        prediction\n",
      "Id                \n",
      "1             10.0\n",
      "6             10.0\n",
      "9             10.0\n",
      "12            10.0\n",
      "13            10.0\n",
      "...            ...\n",
      "177717        10.0\n",
      "177718        10.0\n",
      "177726        10.0\n",
      "177728        10.0\n",
      "177731        10.0\n",
      "\n",
      "[50000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "236c4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sassa_pred_1 = pred.copy()\n",
    "sassa_pred_1['prediction'] = Xtest_Lin_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d7371dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sassa_pred_1.to_csv('/Users/Jamie/sassa_pred_1.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7abc25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Generate predictions for SGD\n",
    "sassa_pred_2 = pred.copy()\n",
    "sassa_pred_2['prediction'] = SGD_predictions\n",
    "sassa_pred_2.to_csv('/Users/Jamie/sassa_pred_2.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "145ea5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now Generate predictions for AdaBoost\n",
    "sassa_pred_3 = pred.copy()\n",
    "sassa_pred_3['prediction'] = AB_predictions\n",
    "sassa_pred_3.to_csv('/Users/Jamie/sassa_pred_3.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_raw.sample\n",
    "sns.pairplot(Xtrain_raw.sample(n = 2, random_state=1), height = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23c0554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value    10.656328\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = Ytrain_raw.mean(axis=0)\n",
    "std = Ytrain_raw.std(axis=0)\n",
    "#mu\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xtrain_raw_copy= Xtrain_raw.copy()\n",
    "#Xtrain_droppedNA = Xtrain_raw_copy.dropna()\n",
    "Xtrain_droppedNA = Xtrain_raw.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe37c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr(Xtrain_droppedNA, 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49366b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "Xtrain_droppedNA = scaler.fit_transform(Xtrain_droppedNA)\n",
    "#df_numeric[df_numeric.columns] = scaler.fit_transform(df_numeric[df_numeric.columns])\n",
    "#print(Xtrain_droppedNA['#A01'].mean())\n",
    "#print(Xtrain_droppedNA['total'].std())\n",
    "\n",
    "plt.figure(figsize=(50,40))\n",
    "#cor = Xtrain_droppedNA.corr(method = 'pearson')\n",
    "#sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(Xtrain_droppedNA.sample(n = 110, random_state=1), height = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
